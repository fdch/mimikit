{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimikit as mmk\n",
    "import h5mapper as h5m\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b115b",
   "metadata": {},
   "source": [
    "# Architecture + Feature => Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7e89f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tp = h5m.TypedFile(\"test.h5\")\n",
    "arch = mmk.WNBlock(blocks=(4,), pad_side=0)\n",
    "feat = mmk.MuLawSignal(sr=16000, normalize=True, q_levels=256)\n",
    "\n",
    "inpt_mods = [feat.input_module(d) for feat, d in zip([feat], chain(arch.hp.dims_dilated, arch.hp.dims_1x1))]\n",
    "out_d = arch.hp.skips_dim if arch.hp.skips_dim is not None else arch.hp.dims_dilated[0]\n",
    "outpt_mods = [feat.output_module(out_d) for feat in [feat]]\n",
    "net = arch.with_io(inpt_mods, outpt_mods)\n",
    "\n",
    "\n",
    "net(torch.randint(0, 256, (4, 32,)), temperature=.95).size(), net.s.args, net.s.full_kwargs, \\\n",
    "net.s.default, net.s.in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5306ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "getters = net.getters(batch_length=32, stride=1, hop_length=1, shift_error=0)\n",
    "batch = (\n",
    "    h5m.Input(proxy=tp.snd, getter=getters['inputs'], transform=feat.transform),\n",
    "    h5m.Target(proxy=tp.snd, getter=getters['targets'], transform=feat.transform),\n",
    ")\n",
    "dl = tp.serve(batch,\n",
    "              shuffle=True,\n",
    "              batch_size=8,\n",
    "              num_workers=8,\n",
    "              pin_memory=True,\n",
    "              persistent_workers=True, # need this!\n",
    "             )\n",
    "\n",
    "# inp, outp = next(iter(dl))\n",
    "# inp.shape, outp.shape, inp, outp, tp.snd[1980:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e2854",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tr_loop = mmk.TrainLoop(\n",
    "    loader=dl,\n",
    "    net=net,\n",
    "    loss_fn=lambda out, trgt: {\"loss\": feat.loss_fn(out, trgt)},\n",
    "    optim=torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    ")\n",
    "\n",
    "class Logs(h5m.TypedFile):\n",
    "     ckpt = h5m.TensorDict(net.state_dict())\n",
    "\n",
    "logs = Logs(\"logs.h5\", mode='w')\n",
    "\n",
    "callbacks = [\n",
    "    mmk.MMKCheckpoint(h5_tensor_dict=logs.ckpt, epochs=1),\n",
    "]\n",
    "logger = mmk.LossLogger(logs)\n",
    "\n",
    "tr_loop.run(max_epochs=5, \n",
    "           logger=logger,\n",
    "           callbacks=callbacks,\n",
    "           limit_train_batches=58)\n",
    "\n",
    "logs.info()\n",
    "logs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3417627",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logs.loss[:], net.load_state_dict(logs.ckpt['epoch=1-step=58']), logs.ckpt.load_hp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27597a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Logs = h5m.typedfile(\"Logs\", {})\n",
    "# logs = Logs(\"logs.h5\", mode='r+')\n",
    "\n",
    "\n",
    "# logs.info()\n",
    "\n",
    "fdict = {\"test\": lambda x: x-1, 'test2': lambda x: x+2}\n",
    "logs.loss.compute(fdict, )\n",
    "\n",
    "# for i in logs.__src__.id[logs.loss.refs[:].astype(np.bool)]:\n",
    "#     print(i)\n",
    "#     res = {k: f(logs.loss.get(i)) for k, f in fdict.items()}\n",
    "#     logs.add(i, res)\n",
    "\n",
    "logs.__src__.id[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.get(\"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b89a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.loss.refs[:].shape, logs.__src__.id[:].shape, logs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73821c6f",
   "metadata": {},
   "source": [
    "# Generate Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960685d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.use_fast_generate = False\n",
    "\n",
    "n_batches = 2\n",
    "batch_size = 8\n",
    "prompt_length = 32\n",
    "n_steps = 100\n",
    "\n",
    "# Gen DataLoader\n",
    "gen_getters = net.getters(batch_length=prompt_length, stride=1, hop_length=1, shift_error=0)\n",
    "gen_batch = (h5m.Input(proxy=tp.snd, getter=gen_getters['inputs'], transform=feat.transform),)\n",
    "gen_dl = tp.serve(gen_batch,\n",
    "                  shuffle=False,\n",
    "                  batch_size=batch_size,\n",
    "                  sampler=torch.randint(0, tp.snd.shape[0], (batch_size*n_batches,),)\n",
    "                 )\n",
    "\n",
    "# Gen Loop\n",
    "outputs = {}\n",
    "loop = mmk.GenerateLoop(\n",
    "    network=net,\n",
    "    dataloader=gen_dl,\n",
    "    interfaces=[\n",
    "        mmk.DynamicDataInterface(\n",
    "            None,\n",
    "            getter=h5m.AsSlice(dim=1, shift=-net.rf, length=net.rf),\n",
    "            setter=mmk.Setter(dim=1)\n",
    "        ),\n",
    "        # temperature\n",
    "        mmk.DynamicDataInterface(\n",
    "            None,\n",
    "            prepare=lambda src: torch.rand(batch_size, n_steps) + 1,\n",
    "            getter=h5m.AsSlice(dim=1, shift=0, length=1),\n",
    "            setter=None,\n",
    "        )\n",
    "    ],\n",
    "    n_batches=n_batches,\n",
    "    n_steps=n_steps,\n",
    "    device='cpu',\n",
    "    process_outputs=lambda out, i: outputs.__setitem__(i, out)\n",
    ")\n",
    "\n",
    "loop.run()\n",
    "\n",
    "len(outputs), outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71633236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}